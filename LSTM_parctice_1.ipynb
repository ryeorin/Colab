{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNY0rmVHiiN+r4N+IM024M+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryeorin/Colab/blob/main/LSTM_parctice_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torchtext"
      ],
      "metadata": {
        "id": "QlRgaS1nDPYw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9HDiKOqC5uK",
        "outputId": "db61d331-ed15-44f1-ba66-e81e97c7d635"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Collecting sentencepiece (from torchtext==0.6.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.0\n",
            "    Uninstalling torchtext-0.16.0:\n",
            "      Successfully uninstalled torchtext-0.16.0\n",
            "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext import data,datasets\n",
        "import torch.nn as nn\n",
        "import torch"
      ],
      "metadata": {
        "id": "fpADUQYfDm1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT=data.Field(sequential=True,batch_first=True,lower=True)\n",
        "LABEL=data.Field(sequential=False,batch_first=True)\n",
        "\n",
        "\n",
        "# 입력되는 데이터를 정형화 하기 위해\n",
        "# sequential : 시퀀스 데이터 여부\n",
        "# use_vocab: 단어 집합을 만들 것인가\n",
        "# lower: 영어 데이터를 전부 소문자화\n",
        "# batch_first: 미니 배치 차원을 맨 앞으로 할 것인가\n",
        "# fix_length: 최대 허용 길이. 이 길이에 맞춰서 패딩"
      ],
      "metadata": {
        "id": "L-sVrOj9DtgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset=datasets.IMDB.splits(TEXT,LABEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHcuPF06EZDc",
        "outputId": "e01219cb-ca5d-4c7e-9092-2b0f08aa137e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:18<00:00, 4.62MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"학습 데이터 크기: \", len(trainset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ewU-XibEkd7",
        "outputId": "45f20c1f-d055-4ffd-aa11-524b1b5d7684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 크기:  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vars(trainset[0])) #딕셔너리 형태로 분리되어 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUYD_RQtFDCP",
        "outputId": "8a19a33f-44fe-4ad6-d4ca-45af62165f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['well,', \"i'll\", 'be', 'honest:', 'it', 'is', 'not', 'exactly', 'a', 'sholay.', 'but', 'you', 'cant', 'get', 'a', 'sholay', 'every', 'week.', 'in', 'fact,', 'you', 'could', 'see', 'distinct', 'signatures', 'of', '\"not', 'without', 'my', 'daughter\"(sally', 'field,', '1991)', 'in', 'this', 'movie.', 'however,', 'as', 'most', '\"inspired\"', 'movies', 'go,', 'this', 'one', 'was', 'a', 'well-inspired', 'one,', 'well', 'handled', 'and', 'well', 'done.', 'nana', 'patekar,', 'as', 'usual,', 'tends', 'to', 'overdo', 'his', 'hysterics,', 'but', 'all', 'others', 'are', 'commendable.', 'specially', 'so', 'about', 'dipti', 'naval:', 'saw', 'her', 'after', 'a', 'long', 'time,', 'but', 'she', \"hasn't\", 'lost', 'any', 'of', 'her', 'grace.', 'in', 'fact,', 'she', 'has', 'performed', 'much', 'better', 'that', 'when', 'i', 'last', 'saw', 'her.', 'another', 'one', 'of', 'the', 'bollywood', 'stars', 'that', 'seem', 'to', 'grow', 'more', 'beautiful', 'as', 'they', 'age?<br', '/><br', '/>all', 'in', 'all,', 'a', 'nice', 'watch.'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainset.fields.items())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJXtDGBQFGjD",
        "outputId": "d6ec7ec0-6008-43ce-aaae-717a9809ff2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_items([('text', <torchtext.data.field.Field object at 0x7b5e475bdba0>), ('label', <torchtext.data.field.Field object at 0x7b5e475be320>)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(trainset,min_freq=10,max_size=10000) # 10번 이상 나온 단어만 단어 집합으로 쓰겠다.\n",
        "\n",
        "print(\"단어 집합 크기:\", len(TEXT.vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSrgaxWPFM4T",
        "outputId": "dcac945e-b5d8-4d57-a204-08eddd6d1eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 크기: 10002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.stoi) # 각 단어별로 인덱스를 부여해줌 <unknown> <> special 토큰"
      ],
      "metadata": {
        "id": "gwfjhUqAF88m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 준비"
      ],
      "metadata": {
        "id": "OQyD3kzVGbI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext import data,datasets"
      ],
      "metadata": {
        "id": "LD88b4NiGYhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED =5\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POCYuAjNGp9Z",
        "outputId": "d4007019-c4ca-4fb9-d78e-0b941e814b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7b5ed9701e10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT=data.Field(sequential=True,batch_first=True,lower=True)\n",
        "LABEL=data.Field(sequential=False,batch_first=True)"
      ],
      "metadata": {
        "id": "E9BwQLB5HB6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, testset=datasets.IMDB.splits(TEXT,LABEL)"
      ],
      "metadata": {
        "id": "1GLwWVSkG5eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(trainset, min_freq=10)\n",
        "LABEL.build_vocab(trainset)"
      ],
      "metadata": {
        "id": "EDsqfKh6HZKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(TEXT.vocab)\n",
        "n_classes=2"
      ],
      "metadata": {
        "id": "e5cGFa0wHm8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"단어 집합 크기:\", len(TEXT.vocab))\n",
        "print(\"클래스의 개수:\",n_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yQifFBXHstr",
        "outputId": "46fdd775-ea15-4549-ecd3-56156c4b6a05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합 크기: 27299\n",
            "클래스의 개수: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(TEXT.vocab.stoi)"
      ],
      "metadata": {
        "id": "WFkHkN5OHz1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training set -> split (train 80%, validation 20%)\n",
        "\n",
        "trainset, validset=trainset.split(split_ratio=0.8)\n",
        "\n",
        "print(\"train 데이터의 크기:\",len(trainset))\n",
        "print(\"valid 데이터의 크기:\",len(validset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKfk_yoiIARo",
        "outputId": "ebd27616-6aad-4763-e9d9-4a350c30038e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 데이터의 크기: 20000\n",
            "valid 데이터의 크기: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter,val_iter,test_iter=data.BucketIterator.splits(\n",
        "    (trainset, validset,testset), batch_size=64,shuffle=True,repeat=False\n",
        ")"
      ],
      "metadata": {
        "id": "_gEGAq5GISU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle 해주면 mini_batch 안에 들어가게 된다."
      ],
      "metadata": {
        "id": "_EmlR9FBJJb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini_batch=next(iter(train_iter)) #train 안에 어떤걸 ??가지고 있는지??\n",
        "\n",
        "print(mini_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3udjEjKJEJm",
        "outputId": "6c9b403d-5704-4d13-c7b0-81208f5d87c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 64]\n",
            "\t[.text]:[torch.LongTensor of size 64x1475]\n",
            "\t[.label]:[torch.LongTensor of size 64]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(mini_batch ,text.shape)\n",
        "print(mini_batch.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE5E0RFTJeEG",
        "outputId": "f7f0372e-5e9e-4ba4-f413-e2dfe9da300e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   10,     7,     3,  ...,     1,     1,     1],\n",
            "        [21067,     0,     0,  ...,     1,     1,     1],\n",
            "        [   52,     7,   371,  ...,     1,     1,     1],\n",
            "        ...,\n",
            "        [    3,  1056,   431,  ...,     1,     1,     1],\n",
            "        [    9,   200,    10,  ...,     1,     1,     1],\n",
            "        [ 1221,  5824,    64,  ...,     1,     1,     1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[학습데이터]: %d [검증데이터]: %d [테스트데이터]: %d [단어수]: %d [클래스]: %d \" % (\n",
        "\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "NhpN5dYgJiml",
        "outputId": "c8b7cb90-d6c5-4a04-e8b7-b000b6c27d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-24d1774fb704>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m print(\"[학습데이터]: %d [검증데이터]: %d [테스트데이터]: %d [단어수]: %d [클래스]: %d \" % (\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m ))\n",
            "\u001b[0;31mTypeError\u001b[0m: not enough arguments for format string"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 정의\n",
        "batch_size=64\n",
        "learning_rate=1e-3\n",
        "n_epochs=10\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-xFuFxwJ7e0",
        "outputId": "5d45cc3e-4c6b-4510-b208-1ed7d870af29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "# 모델 객체화 한 것임? 드롭아웃까지\n",
        "# 그 아래가 모델이 뭐라고?\n",
        "# logit으로 확률값이 나오게 됨\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self,n_layers,hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "    self.n_layers=n_layers\n",
        "    self.hidden_dim=hidden_dim\n",
        "\n",
        "    super(Model,self).__init__()\n",
        "\n",
        "    self.embed=nn.Embeding(n_vocab,embed_dim) # 임베딩으로 변경\n",
        "    self.lstm=nn.LSTM(embed_dim,self.hidden_dim,num_layers=self.n_layers,batch_first=True)\n",
        "    self.out=nn.Linear(self.hidden_dim,n_classes)\n",
        "    self.dropout=nn.Dropout(dropout_p)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x=self.embed(x)\n",
        "\n",
        "    output,(hn,cn)=self.lstm(x)\n",
        "    hn=hn[1]\n",
        "    hn=self.dropout(hn)\n",
        "    logit=self.out(hn)\n",
        "\n",
        "    return logit"
      ],
      "metadata": {
        "id": "tBAmEZAUKT-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, evaluate 함수 정의\n",
        "def train(model, optimizer, train_iter):\n",
        "  model.train()# 모드 변환 중요\n",
        "  for _.mini_batch in enumerate(train_iter):\n",
        "    x,y=mini_batch.text.to(device), mini_batch.label.to(device)\n",
        "    y.data.sub_(1) # 0과 1로 변환 1->0, 2->1\n",
        "\n",
        "    optimizer.zero_grad() #옵티마이저 쓸때 초기화가 안 되어있기 때문에 초기화 시켜줘야함\n",
        "\n",
        "    logit=model(x)\n",
        "    loss=F.corss_entropy(logit,y)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "def evaluate(model, val_iter):\n",
        "  model.eval()\n",
        "  correctes, total_loss=0,0\n",
        "  for mini_batch in val_iter:\n",
        "    x,y = mini_batch.text.to(device), mini_batch.label.to(device)\n",
        "    y.data.sub_(1)\n",
        "\n",
        "    logit=model(x)\n",
        "    loss=F.corss_entropy(logit,y,reduction=\"sum\")\n",
        "    total_loss += loss.item()\n",
        "    corrects +=(logit.max(1)[1].view(y.size()).data==y.data).sum()\n",
        "\n",
        "  avg_loss= total_loss/len(val_iter.dataset)\n",
        "  avg_accuracy=100.0*corrects/len(val_iter.dataset)\n",
        "\n",
        "  return avg_loss, avg_accuracy"
      ],
      "metadata": {
        "id": "T_j9f8ZBL2kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# iterater 마다 미니 배치 넣어줘야되니가 for문 작성해줌\n",
        "# 이벨류에이트 모델 검증하는 거\n",
        "# corrects 맞춘 개수만 입력이 가능\n",
        "# 평균 로스와 정확도"
      ],
      "metadata": {
        "id": "SurHp0BBMLgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Model(2,256,vocab_size=400,n_classes, 0.5).to(device)\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "UnRCWtexN1-t",
        "outputId": "05687a8b-201c-4c5f-f0d0-0e669dcb5356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-f00669c1e2c2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    model=Model(2,256,vocab_size=vocab_size,n_classes=n_classes, 0.5).to(device)\u001b[0m\n\u001b[0m                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model 안에 layer 개수 2개 hidden dim 256 길이\n",
        "# 임베딩 레이어 통해서 단어가\n",
        "# 옵티마이저 안에 모델의 파라미터가 업데이트가 됨"
      ],
      "metadata": {
        "id": "dvjtRZn4N-R4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_loss=None\n",
        "for e in range(1, n_epochs+1):\n",
        "  train(model, optimizer, train_iter)\n",
        "  val_loss, val_accuracy=evaluate(model, val_iter)\n",
        "\n",
        "  print(\"Epoch: %d | Val loss: %.2f | Val accuracy: %.2f\" % (e, val_loss, val_accuracy))\n",
        "\n",
        "  if not best_val_loss or val_loss < best_val_loss:\n",
        "    torch.save(model.state_dict(), './txtclassification.pt')\n",
        "    best_val_loss=val_loss"
      ],
      "metadata": {
        "id": "d93q3SYeOg_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트셋 추론 및 결과 확인"
      ],
      "metadata": {
        "id": "KSuXRRArPr8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('./txtclassification.pt'))\n",
        "test_loss, text_acc=evaluate(model, test_iter)\n",
        "\n",
        "print(\"테스트 오차: %5.2f | 테스트 정확도: %5.2f\" % (text_loss, text_acc))"
      ],
      "metadata": {
        "id": "pIXdEFgEPrYY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}